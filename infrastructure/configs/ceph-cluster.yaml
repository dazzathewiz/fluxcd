---
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: ceph-secret-admin
  namespace: rook-ceph
spec:
  secretStoreRef:
    kind: ClusterSecretStore
    name: onepassword-k3s
  target:
    creationPolicy: Owner
  data:
  - secretKey: adminKey
    remoteRef:
      key:  ceph-admin
      property: adminKey
  - secretKey: adminID
    remoteRef:
      key:  ceph-admin
      property: adminID
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rook-ceph-cluster-helm-chart-value-overrides
  namespace: flux-system
data:
  values.yaml: |-  
    # Default values for a single rook-ceph cluster
    # This is a YAML-formatted file.
    # Declare variables to be passed into your templates.

    # -- Namespace of the main rook operator
    operatorNamespace: rook-ceph

    # -- The metadata.name of the CephCluster CR
    # @default -- The same as the namespace
    clusterName:

    # -- Optional override of the target kubernetes version
    kubeVersion:

    # -- Cluster ceph.conf override
    configOverride:
    # configOverride: |
    #   [global]
    #   mon_allow_pool_delete = true
    #   osd_pool_default_size = 3
    #   osd_pool_default_min_size = 2

    # Installs a debugging toolbox deployment
    toolbox:
      # -- Enable Ceph debugging pod deployment. See [toolbox](../Troubleshooting/ceph-toolbox.md)
      enabled: false
      # -- Toolbox image, defaults to the image used by the Ceph cluster
      image: #quay.io/ceph/ceph:v17.2.6
      # -- Toolbox tolerations
      tolerations: []
      # -- Toolbox affinity
      affinity: {}
      # -- Toolbox resources
      resources:
        limits:
          cpu: "500m"
          memory: "1Gi"
        requests:
          cpu: "100m"
          memory: "128Mi"
      # -- Set the priority class for the toolbox if desired
      priorityClassName:

    monitoring:
      # -- Enable Prometheus integration, will also create necessary RBAC rules to allow Operator to create ServiceMonitors.
      # Monitoring requires Prometheus to be pre-installed
      enabled: false
      # -- Whether to create the Prometheus rules for Ceph alerts
      createPrometheusRules: false
      # -- The namespace in which to create the prometheus rules, if different from the rook cluster namespace.
      # If you have multiple rook-ceph clusters in the same k8s cluster, choose the same namespace (ideally, namespace with prometheus
      # deployed) to set rulesNamespace for all the clusters. Otherwise, you will get duplicate alerts with multiple alert definitions.
      rulesNamespaceOverride:
      # Monitoring settings for external clusters:
      # externalMgrEndpoints: <list of endpoints>
      # externalMgrPrometheusPort: <port>
      # allow adding custom labels and annotations to the prometheus rule
      prometheusRule:
        # -- Labels applied to PrometheusRule
        labels: {}
        # -- Annotations applied to PrometheusRule
        annotations: {}

    # -- Create & use PSP resources. Set this to the same value as the rook-ceph chart.
    pspEnable: false

    # imagePullSecrets option allow to pull docker images from private docker registry. Option will be passed to all service accounts.
    # imagePullSecrets:
    # - name: my-registry-secret

    # All values below are taken from the CephCluster CRD
    # -- Cluster configuration.
    # @default -- See [below](#ceph-cluster-spec)
    cephClusterSpec:
      external:
        enable: true
      crashCollector:
        disable: true
      healthCheck:
        daemonHealth:
          mon:
            disabled: false
            interval: 45s
      # optionally, the ceph-mgr IP address can be passed to gather metric from the prometheus exporter
      # monitoring:
      #   enabled: true
      #   rulesNamespace: rook-ceph
      #   externalMgrEndpoints:
          #- ip: ip
          # externalMgrPrometheusPort: 9283
      monitoring:
        enabled: true
        externalMgrEndpoints:
          - ip: "10.10.10.34"
          - ip: "10.10.10.35"
          - ip: "10.10.10.36"
        externalMgrPrometheusPort: 9283
    
    # ingress: normally goes here

    # CRD Pools normally goes here
    cephBlockPools:
      - name: ceph-blockpool
        storageClass:
          enabled: false
    
    cephFileSystems:
      - name: ceph-filesystem
        storageClass:
          enabled: false
    
    # cephFileSystemVolumeSnapshotClass:
    # cephBlockPoolsVolumeSnapshotClass:
    # cephObjectStores:
    cephObjectStores:
      - name: ceph-objectstore
        storageClass:
          enabled: false
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: rook-ceph-cluster
  namespace: flux-system
spec:
  chart:
    spec:
      chart: rook-ceph-cluster
      version: 1.x.x
      sourceRef:
        kind: HelmRepository
        name: rook-release
        namespace: flux-system
  interval: 30m
  timeout: 10m
  targetNamespace: rook-ceph
  install:
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: -1 # keep trying to remediate
    crds: CreateReplace # Upgrade CRDs on package update
  releaseName: rook-ceph-cluster
  valuesFrom:
  - kind: ConfigMap
    name: rook-ceph-cluster-helm-chart-value-overrides
    valuesKey: values.yaml
